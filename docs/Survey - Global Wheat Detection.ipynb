{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Survey - Global Wheat Detection\n",
    "\n",
    "- 小麦の穂の位置検出コンペ\n",
    "- https://www.kaggle.com/c/global-wheat-detection\n",
    "\n",
    "<img src=\"https://user-images.githubusercontent.com/846237/112433696-f4133b80-8d85-11eb-9f36-b6d20fdeab3e.png\">\n",
    "\n",
    "\n",
    "### 開催期間\n",
    "\n",
    "- 2020.05.05 〜 2020.08.19\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3+5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 今回の要点\n",
    "\n",
    "- 物体検出には<font color=\"red\">Yolo v5</font>がオススメ\n",
    "- ドメインの軽減には<font color=\"red\">Psedo Labeling</font>が有効\n",
    "- 矩形情報のアンサンブルには<font color=\"red\">WBF</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## どんなコンペなの？\n",
    "\n",
    "小麦の画像が与えられるので，穂の箇所を矩形で囲む\n",
    "\n",
    "\n",
    "### 入力例\n",
    "\n",
    "<img src=\"https://user-images.githubusercontent.com/846237/113079521-2bfc0200-9210-11eb-8e68-2e3b955f3c94.png\" width=\"600\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 出力例\n",
    "\n",
    "<img src=\"https://user-images.githubusercontent.com/846237/112435514-2de54180-8d88-11eb-8d2d-7714e1519900.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### どんなデータがあるの？\n",
    "\n",
    "- 📄 `train.csv` - image_id, width(画像の幅), height(画像の高さ), bbox(矩形情報)\n",
    "    - 画像サイズはすべて1024x1024\n",
    "    - `bbox`は`[xmin, ymin, width, height]`\n",
    "- 📄 `sample_submission.csv` - \n",
    "- 📂 `train/` - 訓練用の画像フォルダ, <font color=\"green\">3300以上</font>の画像がある. \n",
    "- 📂 `test/` - テスト用の画像フォルダ, コード提出形式でダウンロードできるのは10枚のみ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 外部データ\n",
    "\n",
    "- SPIKE dataset: https://www.kaggle.com/c/global-wheat-detection/discussion/164346\n",
    "- https://plantimages.nottingham.ac.uk/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## どうやって評価するの？\n",
    "\n",
    "- [IoU](https://www.kaggle.com/c/global-wheat-detection/overview/evaluation)\n",
    "\n",
    "<img src=\"https://user-images.githubusercontent.com/846237/113235060-67b0cd80-92dd-11eb-8f36-2e10d9188b1e.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 検出できると何が嬉しいの？\n",
    "\n",
    "- 農家の収穫時の品質改善や研究者への穂の密度や大きさの情報を提供できるようになる\n",
    "    - つまり，シリアルやトーストなど食事が美味しくなる\n",
    "    - cf. https://www.kaggle.com/c/global-wheat-detection/overview/description\n",
    "\n",
    "<img src=\"https://user-images.githubusercontent.com/846237/113287047-fb0ef080-9327-11eb-9afc-4c97e1adbe89.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## このコンペの難しいところ\n",
    "\n",
    "- 世界中の小麦の穂の画像を集めているので，品種や地域，育成度合いや形がバラバラ\n",
    "- 学習データと評価用のデータに共通となる品種&地域はない\n",
    "    - <font color=\"red\">未知の環境でも運用</font>できるモデルを構築する必要がある\n",
    "- アノテーターのラベルミスがかなりある\n",
    "\n",
    "<img src=\"https://user-images.githubusercontent.com/846237/112433696-f4133b80-8d85-11eb-9f36-b6d20fdeab3e.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## いかにして汎化性能を上げるか？\n",
    "\n",
    "- テストデータは品種も地域も違うので，いかにモデルに品種の違いの情報を組み込むかがポイントとなる\n",
    "- 上位が当然のようにやってるのがPseudo Labeling(疑似ラベリング)\n",
    "\n",
    "### やり方\n",
    "\n",
    "1. 教師となるモデルを訓練データで学習させる\n",
    "2. 教師モデルで提出時にテストデータへ疑似ラベルをつける\n",
    "3. 教師となるモデルより大きいモデルを用意する\n",
    "4. 生徒モデルに訓練データ+疑似ラベル付きテストデータで学習させる\n",
    "5. 学習させたモデルで提出する\n",
    "\n",
    "<img src=\"https://user-images.githubusercontent.com/846237/113270645-ad3cbd00-9314-11eb-96d0-8888b59824e2.png\" width=\"400\">\n",
    "<img src=\"https://user-images.githubusercontent.com/846237/113270572-97c79300-9314-11eb-9298-340f80ff9434.png\" width=\"400\">\n",
    "<img src=\"https://user-images.githubusercontent.com/846237/113270666-b3329e00-9314-11eb-9196-c710d3e1ad3b.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- さきほどのやり方を洗練させた(ノイズを加えた)方法が`Noisy Student`\n",
    "    - この記事がわかりやすい.\n",
    "        - cf. https://ai-scholar.tech/articles/treatise/noisy-student-ai-379\n",
    "        - cf. https://qiita.com/rabbitcaptain/items/a15591ca49dc428223ca\n",
    "    - 追加でやることとしては，ノイズを加えるだけ\n",
    "    - DataAugmentaionの手法を選択する方法[RandAugment](https://arxiv.org/abs/1909.13719)を利用\n",
    "    - 直近開かれたコンペだと当たり前のように使われている\n",
    "<img src=\"https://user-images.githubusercontent.com/846237/113269422-63070c00-9313-11eb-8c44-8c030b49a447.png\" width=\"600\">\n",
    "\n",
    "<img src=\"https://user-images.githubusercontent.com/846237/113270850-df4e1f00-9314-11eb-968c-e08096c5150c.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## ❏ 予備知識\n",
    "\n",
    "- 物体検出のおおまかな流れ\n",
    "- Models\n",
    "    - [Yolo v5](https://github.com/ultralytics/yolov5)\n",
    "        - TODO(nishimori-m): スターターキットのリンクを追加する\n",
    "    - EfficientDet\n",
    "    - ResNeSt\n",
    "        - 物体検出でのbackbone\n",
    "            - cf. https://qiita.com/takoroy/items/07c5039ab12b74137626\n",
    "- Post Processing\n",
    "    - WBF(Weighted boxes fusion)\n",
    "        - https://github.com/ZFTurbo/Weighted-Boxes-Fusion\n",
    "        - 物体検出での矩形情報のアンサンブル方法\n",
    "    - PL(Pseudo Labeling)\n",
    "        - https://www.kaggle.com/ufownl/global-wheat-detection-pseudo-labaling\n",
    "- EMA\n",
    "- Feature Pyramid Net(FPN)\n",
    "    - cf. https://qiita.com/TaigaHasegawa/items/653abc81ac4ee1f0d7b8\n",
    "- Data Augmentations\n",
    "    - clahe\n",
    "        - ヒストグラムが均等になるようコントラストを調整\n",
    "            - 暗いところの小麦の穂を見えやすくするため?\n",
    "    - mixup\n",
    "        - cf. [新たなdata augmentation手法mixupを試してみた](https://qiita.com/yu4u/items/70aa007346ec73b7ff05)\n",
    "    - CoarseDropout\n",
    "        - cf. https://www.kaggle.com/c/siim-isic-melanoma-classification/discussion/169721\n",
    "     - GridMask\n",
    "         - cf. https://ohke.hateblo.jp/entry/2020/06/27/230000\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 物体検出ってどうやって学べばいいの？\n",
    "\n",
    "- Deep Learningが叫ばれる前から研究されていた分野なので，歴史を知りつつ学んだほうが良い気がします．\n",
    "\n",
    "物体検出の歴史については下記リンクがわかりやすいです\n",
    "\n",
    "- [物体検出についての歴史まとめ(1)](https://qiita.com/mshinoda88/items/9770ee671ea27f2c81a9)\n",
    "- [物体検出についての歴史まとめ(2)](https://qiita.com/mshinoda88/items/c7e0967923e3ed47fee5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## よく利用されている物体検出アルゴリズム\n",
    "\n",
    "- ライセンス的に許されるならYolo v5を使えば間違いなさそう(2021年3月時点)\n",
    "- 次善がEfficientDet\n",
    "\n",
    "- アルゴリズム\n",
    "    - 🏆 Yolo v5(3rd)\n",
    "    - 🥈 EfficientDet(1st, 2nd, 6th)\n",
    "    - Faster RCNN\n",
    "- backborn\n",
    "    - ResNeSt\n",
    "    \n",
    "<img src=\"https://user-images.githubusercontent.com/26833433/103594689-455e0e00-4eae-11eb-9cdf-7d753e2ceeeb.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 物体検出のツールキット\n",
    "\n",
    "- [Detectron2](https://github.com/facebookresearch/detectron2)\n",
    "    - Facebook AI Researchによる物体検出ライブラリ\n",
    "- [MMDetection](https://github.com/open-mmlab/mmdetection)\n",
    "    - 物体検出用のツールボックス\n",
    "        - Faster RCNNやMask RCNNなど様々なベンチマーク用のアルゴリズムが使えるようになっている"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Boxes fusion\n",
    "\n",
    "- 🏆  WBF(Weighted boxes fusion)\n",
    "    - https://www.kaggle.com/sreevishnudamodaran/vinbigdata-fusing-bboxes-coco-dataset\n",
    "    - 矩形データのアンサンブル時に利用\n",
    "- NMS\n",
    "- Soft NMS\n",
    "\n",
    "<img src=\"https://user-images.githubusercontent.com/846237/113249792-4c07f000-92fa-11eb-86ec-e8758455b4ac.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 学習時の画像サイズ\n",
    "\n",
    "- 1024x1024(1st, 2nd, 5th)\n",
    "- 768x768(1st)\n",
    "- 512x512(3rd)\n",
    "\n",
    "3rdは性能の良いYolo v5を使っちゃってるので，サイズとしてはそのままの1024x1024が良さそう"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data Augmentation\n",
    "\n",
    "- CutMix(後述)\n",
    "- Custom mosaic augmentation(後述)\n",
    "- MixUp\n",
    "- crop, hue, random brightness/contrast\n",
    "- to gray\n",
    "- vertical and horizontal flip\n",
    "- random rotate 90\n",
    "- cutout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### CutMix\n",
    "\n",
    "- Data augmentationの一種\n",
    "- Cutout + Mixupを行って一枚の画像にする\n",
    "\n",
    "<img src=\"https://user-images.githubusercontent.com/846237/113252174-73f95280-92fe-11eb-861c-25c6210acf61.png\">\n",
    "\n",
    "cf. https://github.com/clovaai/CutMix-PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Custom mosaic augmentation\n",
    "\n",
    "- cf. https://www.kaggle.com/c/global-wheat-detection/discussion/172418\n",
    "- 4つの画像を切り取って一枚の画像を作成\n",
    "- 1stが試した方法\n",
    "- CutMixの代わりに利用\n",
    "\n",
    "<img src=\"https://user-images.githubusercontent.com/846237/112433819-23c24380-8d86-11eb-8ab3-a86370377bf2.png\" width=\"600\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Optimizer\n",
    "\n",
    "- AdamW\n",
    "- 余談: 最近，SAMと呼ばれるオプティマイザが良いらしい．\n",
    "    - cf. [SoTAを総なめ！衝撃のオプティマイザー「SAM」爆誕&解説！](https://qiita.com/omiita/items/f24e4f06ae89115d248e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Learning Rate Scheduler\n",
    "\n",
    "- [Cosine Annealing](https://paperswithcode.com/method/cosine-annealing)\n",
    "\n",
    "<img src=\"https://user-images.githubusercontent.com/846237/113264379-ddcd2880-930d-11eb-8b1f-7339878b9a63.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## コンペ特有の知識\n",
    "\n",
    "- ジグソーパズル\n",
    "    - このコンペでは大きな画像を分割することでデータセットを作成している\n",
    "        - つなぎ合わせることで，性能改善が可能\n",
    "    - cf. https://github.com/lRomul/argus-tgs-salt/blob/master/mosaic/create_mosaic.py\n",
    "    - 塩コンペでも同様のテクニックが有効だった\n",
    "        - https://www.kaggle.com/c/tgs-salt-identification-challenge/overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## このコンペで効果的なこと\n",
    "\n",
    "- 上位陣のモデルはYolo v5かEfficientDetのほぼ2択\n",
    "- 検出時のしきい値を低く設定(0.1)するとスコアが改善\n",
    "- 1stと2ndはData Augmentationと外部データの差が大きそう\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 注意事項\n",
    "\n",
    "- MITライセンスのみ可ということで，性能が良いがGNUライセンスであるYolo v5を使って良いか結構揉めた\n",
    "    - TensorflowとかPyTorchも内部のライブラリにはMITライセンス以外が使われているけど，それは良いのかどうか"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## スターターキット\n",
    "\n",
    "- Yolo v5 + Pseudo Labeling\n",
    "    - https://www.kaggle.com/nvnnghia/yolov5-pseudo-labeling/notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Top Solutions\n",
    "\n",
    "\n",
    "- 1st - https://www.kaggle.com/c/global-wheat-detection/discussion/172418\n",
    "    - code\n",
    "        - https://github.com/rwightman/efficientdet-pytorch\n",
    "    - dataset\n",
    "        - image solution\n",
    "            - 1024x1024 for EfficientDet D7(Fold 0,1,2,3,4)\n",
    "            - 768x768 for EfficientDet D7(Fold 1, 3)\n",
    "            - 512x512 for EfficientDet D5(Fold 4)\n",
    "        - external data\n",
    "            - https://www.kaggle.com/c/global-wheat-detection/discussion/164346)\n",
    "            - https://plantimages.nottingham.ac.uk/\n",
    "        - cleaning\n",
    "            - 縦横のどちらかが10px以下の矩形は除外\n",
    "    - models\n",
    "        - <font color='red'>EfficientDet D5&D7</font>, <font color='red'>Faster RCNN FPN</font>\n",
    "    - train\n",
    "        - batch size\n",
    "            - 8: EfficientDet D7(image size: 768)\n",
    "            - 20: Faster FPN ResNet 152(image size: 1024)\n",
    "        - optimizer\n",
    "            - adam for EfficientDet\n",
    "                - learning rate: 5e-4\n",
    "            - sgd for FasterRCNN\n",
    "                - learning rate: 5e-3\n",
    "        - LR scheduler:\n",
    "            - cosine-annealing\n",
    "        - augmentation\n",
    "            - Custom mosaic augmentation\n",
    "            - MixUp\n",
    "    - ensemble\n",
    "        - 8 TTA(vflip x hflip x rotate90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "- 2nd - https://www.kaggle.com/c/global-wheat-detection/discussion/175961\n",
    "    - code\n",
    "        - https://github.com/liaopeiyuan/TransferDet\n",
    "    - model\n",
    "        - <font color='red'>EfficientDet - D6</font>(pretrained w/ COCO dataset)\n",
    "            - D4〜D7まで試してD6が性能が一番良かった\n",
    "    - dataset\n",
    "        - image resolution: 1024x1024\n",
    "    - train\n",
    "        - augmentation\n",
    "            - crop, hue, random brightness/contrast\n",
    "            - to gray\n",
    "            - vertical and horizontal flip\n",
    "            - random rotate 90\n",
    "            - cutout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "- 3rd - https://www.kaggle.com/c/global-wheat-detection/discussion/179055\n",
    "    - code\n",
    "        - https://github.com/ufownl/global-wheat-detection\n",
    "    - model\n",
    "        - <font color='red'>Yolo v5</font>\n",
    "            - backbone: Darknet 53\n",
    "    - train\n",
    "        - max epochs: 9\n",
    "        - learning rate: 0.001\n",
    "        - batch size: 8\n",
    "        - image resolution: 512x512\n",
    "        - threshold: 0.1(物体検出のためのしきい値)\n",
    "        - pseudo labeling\n",
    "            - cf. https://www.kaggle.com/ufownl/global-wheat-detection-pseudo-labaling\n",
    "    - post processing\n",
    "        - TTAにWBF(Weighted boxes fusion)を利用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "- 5th - https://www.kaggle.com/c/global-wheat-detection/discussion/172458\n",
    "    - blog(日本語)\n",
    "        - https://acro-engineer.hatenablog.com/entry/2020/08/21/175617\n",
    "    - dataset\n",
    "        - image resolution: 1024x1024\n",
    "    - models\n",
    "        - <font color='red'>EfficientDet D3 - D5</font>\n",
    "    - train\n",
    "        - 5 folds\n",
    "        - optimizer: AdamW\n",
    "        - max epoichs: 100\n",
    "        - batch size: 640\n",
    "        - pseudo labeling\n",
    "        - augmentation:\n",
    "            - mixup, mosaic, scale\n",
    "            - hue, brightness\n",
    "            - grid mask\n",
    "                - cf. https://arxiv.org/abs/2001.04086\n",
    "    - misc\n",
    "        - threshold: 検出時のしきい値を0.1にすれば，0.695出ていたらしい"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "- 9th - https://www.kaggle.com/c/global-wheat-detection/discussion/172569\n",
    "    - code: \n",
    "        - https://github.com/amirassov/kaggle-global-wheat-detection\n",
    "    - dataset\n",
    "        - external data\n",
    "            - https://www.kaggle.com/c/global-wheat-detection/discussion/164346\n",
    "   　- model\n",
    "        - <font color='red'>MMDetection</font> \n",
    "            - cf. https://github.com/open-mmlab/mmdetection\n",
    "    - train:\n",
    "        - augmentaion\n",
    "            - hflip, scale, shift, rotate90\n",
    "            - brightness/contrast, hue saturation, rgb shift\n",
    "            - random gamma\n",
    "            - clahe\n",
    "            - blur, motion blur\n",
    "            - gauss noise\n",
    "            - image compression\n",
    "            - coarse dropout\n",
    "            \n",
    "<img src=\"https://user-images.githubusercontent.com/846237/113238334-8ade7b80-92e3-11eb-840a-027a86d4fcc7.png\" width=\"600\">\n",
    "<img src=\"https://user-images.githubusercontent.com/846237/113238321-81edaa00-92e3-11eb-879e-be5e2cdc0d13.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "- 16th - https://www.kaggle.com/c/global-wheat-detection/discussion/172567\n",
    "    - train\n",
    "        - augmentaiton\n",
    "            - scale, mosaic, mixup, crop, cutout, hue, brightness, clahe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Top Notebooks\n",
    "\n",
    "- 2nd, https://www.kaggle.com/alexanderliao/effdet-d6-pl-s-bn-r-bb-a3-usa-eval-94-13-db\n",
    "    - EfficientDet - D6\n",
    "- 3rd, https://www.kaggle.com/x2x21x21x21/3rd-place-solution\n",
    "- 6th - https://www.kaggle.com/stonewst98/what-a-pity-only-0-0001-away-from-0-77\n",
    "    - Effficient Det\n",
    "- 9th - https://www.kaggle.com/amiras/pseudo-ensemble-detectors-3-st-universenet-r10\n",
    "- 13th - https://www.kaggle.com/dpyrtfq2372/efficientdet-with-double-psudo-labeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 次にやると良さそうなコンペ\n",
    "\n",
    "- VinBigData Chest X-ray Abnormalities Detection\n",
    "   - 物体検出コンペ\n",
    "   - 医師ごとに矩形の領域がバラバラなので，どう統合していくか学べます\n",
    "   - 胸部X線からの異常所見の分類\n",
    "   - https://www.kaggle.com/c/vinbigdata-chest-xray-abnormalities-detection"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
