{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Survey - Global Wheat Detection\n",
    "\n",
    "- å°éº¦ã®ç©‚ã®ä½ç½®æ¤œå‡ºã‚³ãƒ³ãƒš\n",
    "- https://www.kaggle.com/c/global-wheat-detection\n",
    "\n",
    "<img src=\"https://user-images.githubusercontent.com/846237/112433696-f4133b80-8d85-11eb-9f36-b6d20fdeab3e.png\">\n",
    "\n",
    "\n",
    "### é–‹å‚¬æœŸé–“\n",
    "\n",
    "- 2020.05.05 ã€œ 2020.08.19\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3+5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ä»Šå›ã®è¦ç‚¹\n",
    "\n",
    "- ç‰©ä½“æ¤œå‡ºã«ã¯<font color=\"red\">Yolo v5</font>ãŒã‚ªã‚¹ã‚¹ãƒ¡\n",
    "- ãƒ‰ãƒ¡ã‚¤ãƒ³ã®è»½æ¸›ã«ã¯<font color=\"red\">Psedo Labeling</font>ãŒæœ‰åŠ¹\n",
    "- çŸ©å½¢æƒ…å ±ã®ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã«ã¯<font color=\"red\">WBF</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ã©ã‚“ãªã‚³ãƒ³ãƒšãªã®ï¼Ÿ\n",
    "\n",
    "å°éº¦ã®ç”»åƒãŒä¸ãˆã‚‰ã‚Œã‚‹ã®ã§ï¼Œç©‚ã®ç®‡æ‰€ã‚’çŸ©å½¢ã§å›²ã‚€\n",
    "\n",
    "\n",
    "### å…¥åŠ›ä¾‹\n",
    "\n",
    "<img src=\"https://user-images.githubusercontent.com/846237/113079521-2bfc0200-9210-11eb-8e68-2e3b955f3c94.png\" width=\"600\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### å‡ºåŠ›ä¾‹\n",
    "\n",
    "<img src=\"https://user-images.githubusercontent.com/846237/112435514-2de54180-8d88-11eb-8d2d-7714e1519900.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### ã©ã‚“ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹ã®ï¼Ÿ\n",
    "\n",
    "- ğŸ“„ `train.csv` - image_id, width(ç”»åƒã®å¹…), height(ç”»åƒã®é«˜ã•), bbox(çŸ©å½¢æƒ…å ±)\n",
    "    - ç”»åƒã‚µã‚¤ã‚ºã¯ã™ã¹ã¦1024x1024\n",
    "    - `bbox`ã¯`[xmin, ymin, width, height]`\n",
    "- ğŸ“„ `sample_submission.csv` - \n",
    "- ğŸ“‚ `train/` - è¨“ç·´ç”¨ã®ç”»åƒãƒ•ã‚©ãƒ«ãƒ€, <font color=\"green\">3300ä»¥ä¸Š</font>ã®ç”»åƒãŒã‚ã‚‹. \n",
    "- ğŸ“‚ `test/` - ãƒ†ã‚¹ãƒˆç”¨ã®ç”»åƒãƒ•ã‚©ãƒ«ãƒ€, ã‚³ãƒ¼ãƒ‰æå‡ºå½¢å¼ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã§ãã‚‹ã®ã¯10æšã®ã¿"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿\n",
    "\n",
    "- SPIKE dataset: https://www.kaggle.com/c/global-wheat-detection/discussion/164346\n",
    "- https://plantimages.nottingham.ac.uk/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ã©ã†ã‚„ã£ã¦è©•ä¾¡ã™ã‚‹ã®ï¼Ÿ\n",
    "\n",
    "- [IoU](https://www.kaggle.com/c/global-wheat-detection/overview/evaluation)\n",
    "\n",
    "<img src=\"https://user-images.githubusercontent.com/846237/113235060-67b0cd80-92dd-11eb-8f36-2e10d9188b1e.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## æ¤œå‡ºã§ãã‚‹ã¨ä½•ãŒå¬‰ã—ã„ã®ï¼Ÿ\n",
    "\n",
    "- è¾²å®¶ã®åç©«æ™‚ã®å“è³ªæ”¹å–„ã‚„ç ”ç©¶è€…ã¸ã®ç©‚ã®å¯†åº¦ã‚„å¤§ãã•ã®æƒ…å ±ã‚’æä¾›ã§ãã‚‹ã‚ˆã†ã«ãªã‚‹\n",
    "    - ã¤ã¾ã‚Šï¼Œã‚·ãƒªã‚¢ãƒ«ã‚„ãƒˆãƒ¼ã‚¹ãƒˆãªã©é£Ÿäº‹ãŒç¾å‘³ã—ããªã‚‹\n",
    "    - cf. https://www.kaggle.com/c/global-wheat-detection/overview/description\n",
    "\n",
    "<img src=\"https://user-images.githubusercontent.com/846237/113287047-fb0ef080-9327-11eb-9afc-4c97e1adbe89.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ã“ã®ã‚³ãƒ³ãƒšã®é›£ã—ã„ã¨ã“ã‚\n",
    "\n",
    "- ä¸–ç•Œä¸­ã®å°éº¦ã®ç©‚ã®ç”»åƒã‚’é›†ã‚ã¦ã„ã‚‹ã®ã§ï¼Œå“ç¨®ã‚„åœ°åŸŸï¼Œè‚²æˆåº¦åˆã„ã‚„å½¢ãŒãƒãƒ©ãƒãƒ©\n",
    "- å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨è©•ä¾¡ç”¨ã®ãƒ‡ãƒ¼ã‚¿ã«å…±é€šã¨ãªã‚‹å“ç¨®&åœ°åŸŸã¯ãªã„\n",
    "    - <font color=\"red\">æœªçŸ¥ã®ç’°å¢ƒã§ã‚‚é‹ç”¨</font>ã§ãã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã™ã‚‹å¿…è¦ãŒã‚ã‚‹\n",
    "- ã‚¢ãƒãƒ†ãƒ¼ã‚¿ãƒ¼ã®ãƒ©ãƒ™ãƒ«ãƒŸã‚¹ãŒã‹ãªã‚Šã‚ã‚‹\n",
    "\n",
    "<img src=\"https://user-images.githubusercontent.com/846237/112433696-f4133b80-8d85-11eb-9f36-b6d20fdeab3e.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ã„ã‹ã«ã—ã¦æ±åŒ–æ€§èƒ½ã‚’ä¸Šã’ã‚‹ã‹ï¼Ÿ\n",
    "\n",
    "- ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã¯å“ç¨®ã‚‚åœ°åŸŸã‚‚é•ã†ã®ã§ï¼Œã„ã‹ã«ãƒ¢ãƒ‡ãƒ«ã«å“ç¨®ã®é•ã„ã®æƒ…å ±ã‚’çµ„ã¿è¾¼ã‚€ã‹ãŒãƒã‚¤ãƒ³ãƒˆã¨ãªã‚‹\n",
    "- ä¸Šä½ãŒå½“ç„¶ã®ã‚ˆã†ã«ã‚„ã£ã¦ã‚‹ã®ãŒPseudo Labeling(ç–‘ä¼¼ãƒ©ãƒ™ãƒªãƒ³ã‚°)\n",
    "\n",
    "### ã‚„ã‚Šæ–¹\n",
    "\n",
    "1. æ•™å¸«ã¨ãªã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’ã•ã›ã‚‹\n",
    "2. æ•™å¸«ãƒ¢ãƒ‡ãƒ«ã§æå‡ºæ™‚ã«ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã¸ç–‘ä¼¼ãƒ©ãƒ™ãƒ«ã‚’ã¤ã‘ã‚‹\n",
    "3. æ•™å¸«ã¨ãªã‚‹ãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šå¤§ãã„ãƒ¢ãƒ‡ãƒ«ã‚’ç”¨æ„ã™ã‚‹\n",
    "4. ç”Ÿå¾’ãƒ¢ãƒ‡ãƒ«ã«è¨“ç·´ãƒ‡ãƒ¼ã‚¿+ç–‘ä¼¼ãƒ©ãƒ™ãƒ«ä»˜ããƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’ã•ã›ã‚‹\n",
    "5. å­¦ç¿’ã•ã›ãŸãƒ¢ãƒ‡ãƒ«ã§æå‡ºã™ã‚‹\n",
    "\n",
    "<img src=\"https://user-images.githubusercontent.com/846237/113270645-ad3cbd00-9314-11eb-96d0-8888b59824e2.png\" width=\"400\">\n",
    "<img src=\"https://user-images.githubusercontent.com/846237/113270572-97c79300-9314-11eb-9298-340f80ff9434.png\" width=\"400\">\n",
    "<img src=\"https://user-images.githubusercontent.com/846237/113270666-b3329e00-9314-11eb-9196-c710d3e1ad3b.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- ã•ãã»ã©ã®ã‚„ã‚Šæ–¹ã‚’æ´—ç·´ã•ã›ãŸ(ãƒã‚¤ã‚ºã‚’åŠ ãˆãŸ)æ–¹æ³•ãŒ`Noisy Student`\n",
    "    - ã“ã®è¨˜äº‹ãŒã‚ã‹ã‚Šã‚„ã™ã„.\n",
    "        - cf. https://ai-scholar.tech/articles/treatise/noisy-student-ai-379\n",
    "        - cf. https://qiita.com/rabbitcaptain/items/a15591ca49dc428223ca\n",
    "    - è¿½åŠ ã§ã‚„ã‚‹ã“ã¨ã¨ã—ã¦ã¯ï¼Œãƒã‚¤ã‚ºã‚’åŠ ãˆã‚‹ã ã‘\n",
    "    - DataAugmentaionã®æ‰‹æ³•ã‚’é¸æŠã™ã‚‹æ–¹æ³•[RandAugment](https://arxiv.org/abs/1909.13719)ã‚’åˆ©ç”¨\n",
    "    - ç›´è¿‘é–‹ã‹ã‚ŒãŸã‚³ãƒ³ãƒšã ã¨å½“ãŸã‚Šå‰ã®ã‚ˆã†ã«ä½¿ã‚ã‚Œã¦ã„ã‚‹\n",
    "<img src=\"https://user-images.githubusercontent.com/846237/113269422-63070c00-9313-11eb-8c44-8c030b49a447.png\" width=\"600\">\n",
    "\n",
    "<img src=\"https://user-images.githubusercontent.com/846237/113270850-df4e1f00-9314-11eb-968c-e08096c5150c.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## â äºˆå‚™çŸ¥è­˜\n",
    "\n",
    "- ç‰©ä½“æ¤œå‡ºã®ãŠãŠã¾ã‹ãªæµã‚Œ\n",
    "- Models\n",
    "    - [Yolo v5](https://github.com/ultralytics/yolov5)\n",
    "        - TODO(nishimori-m): ã‚¹ã‚¿ãƒ¼ã‚¿ãƒ¼ã‚­ãƒƒãƒˆã®ãƒªãƒ³ã‚¯ã‚’è¿½åŠ ã™ã‚‹\n",
    "    - EfficientDet\n",
    "    - ResNeSt\n",
    "        - ç‰©ä½“æ¤œå‡ºã§ã®backbone\n",
    "            - cf. https://qiita.com/takoroy/items/07c5039ab12b74137626\n",
    "- Post Processing\n",
    "    - WBF(Weighted boxes fusion)\n",
    "        - https://github.com/ZFTurbo/Weighted-Boxes-Fusion\n",
    "        - ç‰©ä½“æ¤œå‡ºã§ã®çŸ©å½¢æƒ…å ±ã®ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æ–¹æ³•\n",
    "    - PL(Pseudo Labeling)\n",
    "        - https://www.kaggle.com/ufownl/global-wheat-detection-pseudo-labaling\n",
    "- EMA\n",
    "- Feature Pyramid Net(FPN)\n",
    "    - cf. https://qiita.com/TaigaHasegawa/items/653abc81ac4ee1f0d7b8\n",
    "- Data Augmentations\n",
    "    - clahe\n",
    "        - ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ãŒå‡ç­‰ã«ãªã‚‹ã‚ˆã†ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆã‚’èª¿æ•´\n",
    "            - æš—ã„ã¨ã“ã‚ã®å°éº¦ã®ç©‚ã‚’è¦‹ãˆã‚„ã™ãã™ã‚‹ãŸã‚?\n",
    "    - mixup\n",
    "        - cf. [æ–°ãŸãªdata augmentationæ‰‹æ³•mixupã‚’è©¦ã—ã¦ã¿ãŸ](https://qiita.com/yu4u/items/70aa007346ec73b7ff05)\n",
    "    - CoarseDropout\n",
    "        - cf. https://www.kaggle.com/c/siim-isic-melanoma-classification/discussion/169721\n",
    "     - GridMask\n",
    "         - cf. https://ohke.hateblo.jp/entry/2020/06/27/230000\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ç‰©ä½“æ¤œå‡ºã£ã¦ã©ã†ã‚„ã£ã¦å­¦ã¹ã°ã„ã„ã®ï¼Ÿ\n",
    "\n",
    "- Deep LearningãŒå«ã°ã‚Œã‚‹å‰ã‹ã‚‰ç ”ç©¶ã•ã‚Œã¦ã„ãŸåˆ†é‡ãªã®ã§ï¼Œæ­´å²ã‚’çŸ¥ã‚Šã¤ã¤å­¦ã‚“ã ã»ã†ãŒè‰¯ã„æ°—ãŒã—ã¾ã™ï¼\n",
    "\n",
    "ç‰©ä½“æ¤œå‡ºã®æ­´å²ã«ã¤ã„ã¦ã¯ä¸‹è¨˜ãƒªãƒ³ã‚¯ãŒã‚ã‹ã‚Šã‚„ã™ã„ã§ã™\n",
    "\n",
    "- [ç‰©ä½“æ¤œå‡ºã«ã¤ã„ã¦ã®æ­´å²ã¾ã¨ã‚(1)](https://qiita.com/mshinoda88/items/9770ee671ea27f2c81a9)\n",
    "- [ç‰©ä½“æ¤œå‡ºã«ã¤ã„ã¦ã®æ­´å²ã¾ã¨ã‚(2)](https://qiita.com/mshinoda88/items/c7e0967923e3ed47fee5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ã‚ˆãåˆ©ç”¨ã•ã‚Œã¦ã„ã‚‹ç‰©ä½“æ¤œå‡ºã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ \n",
    "\n",
    "- ãƒ©ã‚¤ã‚»ãƒ³ã‚¹çš„ã«è¨±ã•ã‚Œã‚‹ãªã‚‰Yolo v5ã‚’ä½¿ãˆã°é–“é•ã„ãªã•ãã†(2021å¹´3æœˆæ™‚ç‚¹)\n",
    "- æ¬¡å–„ãŒEfficientDet\n",
    "\n",
    "- ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ \n",
    "    - ğŸ† Yolo v5(3rd)\n",
    "    - ğŸ¥ˆ EfficientDet(1st, 2nd, 6th)\n",
    "    - Faster RCNN\n",
    "- backborn\n",
    "    - ResNeSt\n",
    "    \n",
    "<img src=\"https://user-images.githubusercontent.com/26833433/103594689-455e0e00-4eae-11eb-9cdf-7d753e2ceeeb.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ç‰©ä½“æ¤œå‡ºã®ãƒ„ãƒ¼ãƒ«ã‚­ãƒƒãƒˆ\n",
    "\n",
    "- [Detectron2](https://github.com/facebookresearch/detectron2)\n",
    "    - Facebook AI Researchã«ã‚ˆã‚‹ç‰©ä½“æ¤œå‡ºãƒ©ã‚¤ãƒ–ãƒ©ãƒª\n",
    "- [MMDetection](https://github.com/open-mmlab/mmdetection)\n",
    "    - ç‰©ä½“æ¤œå‡ºç”¨ã®ãƒ„ãƒ¼ãƒ«ãƒœãƒƒã‚¯ã‚¹\n",
    "        - Faster RCNNã‚„Mask RCNNãªã©æ§˜ã€…ãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ç”¨ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãŒä½¿ãˆã‚‹ã‚ˆã†ã«ãªã£ã¦ã„ã‚‹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Boxes fusion\n",
    "\n",
    "- ğŸ†  WBF(Weighted boxes fusion)\n",
    "    - https://www.kaggle.com/sreevishnudamodaran/vinbigdata-fusing-bboxes-coco-dataset\n",
    "    - çŸ©å½¢ãƒ‡ãƒ¼ã‚¿ã®ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æ™‚ã«åˆ©ç”¨\n",
    "- NMS\n",
    "- Soft NMS\n",
    "\n",
    "<img src=\"https://user-images.githubusercontent.com/846237/113249792-4c07f000-92fa-11eb-86ec-e8758455b4ac.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## å­¦ç¿’æ™‚ã®ç”»åƒã‚µã‚¤ã‚º\n",
    "\n",
    "- 1024x1024(1st, 2nd, 5th)\n",
    "- 768x768(1st)\n",
    "- 512x512(3rd)\n",
    "\n",
    "3rdã¯æ€§èƒ½ã®è‰¯ã„Yolo v5ã‚’ä½¿ã£ã¡ã‚ƒã£ã¦ã‚‹ã®ã§ï¼Œã‚µã‚¤ã‚ºã¨ã—ã¦ã¯ãã®ã¾ã¾ã®1024x1024ãŒè‰¯ã•ãã†"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data Augmentation\n",
    "\n",
    "- CutMix(å¾Œè¿°)\n",
    "- Custom mosaic augmentation(å¾Œè¿°)\n",
    "- MixUp\n",
    "- crop, hue, random brightness/contrast\n",
    "- to gray\n",
    "- vertical and horizontal flip\n",
    "- random rotate 90\n",
    "- cutout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### CutMix\n",
    "\n",
    "- Data augmentationã®ä¸€ç¨®\n",
    "- Cutout + Mixupã‚’è¡Œã£ã¦ä¸€æšã®ç”»åƒã«ã™ã‚‹\n",
    "\n",
    "<img src=\"https://user-images.githubusercontent.com/846237/113252174-73f95280-92fe-11eb-861c-25c6210acf61.png\">\n",
    "\n",
    "cf. https://github.com/clovaai/CutMix-PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Custom mosaic augmentation\n",
    "\n",
    "- cf. https://www.kaggle.com/c/global-wheat-detection/discussion/172418\n",
    "- 4ã¤ã®ç”»åƒã‚’åˆ‡ã‚Šå–ã£ã¦ä¸€æšã®ç”»åƒã‚’ä½œæˆ\n",
    "- 1stãŒè©¦ã—ãŸæ–¹æ³•\n",
    "- CutMixã®ä»£ã‚ã‚Šã«åˆ©ç”¨\n",
    "\n",
    "<img src=\"https://user-images.githubusercontent.com/846237/112433819-23c24380-8d86-11eb-8ab3-a86370377bf2.png\" width=\"600\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Optimizer\n",
    "\n",
    "- AdamW\n",
    "- ä½™è«‡: æœ€è¿‘ï¼ŒSAMã¨å‘¼ã°ã‚Œã‚‹ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãŒè‰¯ã„ã‚‰ã—ã„ï¼\n",
    "    - cf. [SoTAã‚’ç·ãªã‚ï¼è¡æ’ƒã®ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼ã€ŒSAMã€çˆ†èª•&è§£èª¬ï¼](https://qiita.com/omiita/items/f24e4f06ae89115d248e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Learning Rate Scheduler\n",
    "\n",
    "- [Cosine Annealing](https://paperswithcode.com/method/cosine-annealing)\n",
    "\n",
    "<img src=\"https://user-images.githubusercontent.com/846237/113264379-ddcd2880-930d-11eb-8b1f-7339878b9a63.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ã‚³ãƒ³ãƒšç‰¹æœ‰ã®çŸ¥è­˜\n",
    "\n",
    "- ã‚¸ã‚°ã‚½ãƒ¼ãƒ‘ã‚ºãƒ«\n",
    "    - ã“ã®ã‚³ãƒ³ãƒšã§ã¯å¤§ããªç”»åƒã‚’åˆ†å‰²ã™ã‚‹ã“ã¨ã§ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆã—ã¦ã„ã‚‹\n",
    "        - ã¤ãªãåˆã‚ã›ã‚‹ã“ã¨ã§ï¼Œæ€§èƒ½æ”¹å–„ãŒå¯èƒ½\n",
    "    - cf. https://github.com/lRomul/argus-tgs-salt/blob/master/mosaic/create_mosaic.py\n",
    "    - å¡©ã‚³ãƒ³ãƒšã§ã‚‚åŒæ§˜ã®ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯ãŒæœ‰åŠ¹ã ã£ãŸ\n",
    "        - https://www.kaggle.com/c/tgs-salt-identification-challenge/overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ã“ã®ã‚³ãƒ³ãƒšã§åŠ¹æœçš„ãªã“ã¨\n",
    "\n",
    "- ä¸Šä½é™£ã®ãƒ¢ãƒ‡ãƒ«ã¯Yolo v5ã‹EfficientDetã®ã»ã¼2æŠ\n",
    "- æ¤œå‡ºæ™‚ã®ã—ãã„å€¤ã‚’ä½ãè¨­å®š(0.1)ã™ã‚‹ã¨ã‚¹ã‚³ã‚¢ãŒæ”¹å–„\n",
    "- 1stã¨2ndã¯Data Augmentationã¨å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿ã®å·®ãŒå¤§ããã†\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## æ³¨æ„äº‹é …\n",
    "\n",
    "- MITãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã®ã¿å¯ã¨ã„ã†ã“ã¨ã§ï¼Œæ€§èƒ½ãŒè‰¯ã„ãŒGNUãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã§ã‚ã‚‹Yolo v5ã‚’ä½¿ã£ã¦è‰¯ã„ã‹çµæ§‹æ‰ã‚ãŸ\n",
    "    - Tensorflowã¨ã‹PyTorchã‚‚å†…éƒ¨ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã«ã¯MITãƒ©ã‚¤ã‚»ãƒ³ã‚¹ä»¥å¤–ãŒä½¿ã‚ã‚Œã¦ã„ã‚‹ã‘ã©ï¼Œãã‚Œã¯è‰¯ã„ã®ã‹ã©ã†ã‹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ã‚¹ã‚¿ãƒ¼ã‚¿ãƒ¼ã‚­ãƒƒãƒˆ\n",
    "\n",
    "- Yolo v5 + Pseudo Labeling\n",
    "    - https://www.kaggle.com/nvnnghia/yolov5-pseudo-labeling/notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Top Solutions\n",
    "\n",
    "\n",
    "- 1st - https://www.kaggle.com/c/global-wheat-detection/discussion/172418\n",
    "    - code\n",
    "        - https://github.com/rwightman/efficientdet-pytorch\n",
    "    - dataset\n",
    "        - image solution\n",
    "            - 1024x1024 for EfficientDet D7(Fold 0,1,2,3,4)\n",
    "            - 768x768 for EfficientDet D7(Fold 1, 3)\n",
    "            - 512x512 for EfficientDet D5(Fold 4)\n",
    "        - external data\n",
    "            - https://www.kaggle.com/c/global-wheat-detection/discussion/164346)\n",
    "            - https://plantimages.nottingham.ac.uk/\n",
    "        - cleaning\n",
    "            - ç¸¦æ¨ªã®ã©ã¡ã‚‰ã‹ãŒ10pxä»¥ä¸‹ã®çŸ©å½¢ã¯é™¤å¤–\n",
    "    - models\n",
    "        - <font color='red'>EfficientDet D5&D7</font>, <font color='red'>Faster RCNN FPN</font>\n",
    "    - train\n",
    "        - batch size\n",
    "            - 8: EfficientDet D7(image size: 768)\n",
    "            - 20: Faster FPN ResNet 152(image size: 1024)\n",
    "        - optimizer\n",
    "            - adam for EfficientDet\n",
    "                - learning rate: 5e-4\n",
    "            - sgd for FasterRCNN\n",
    "                - learning rate: 5e-3\n",
    "        - LR scheduler:\n",
    "            - cosine-annealing\n",
    "        - augmentation\n",
    "            - Custom mosaic augmentation\n",
    "            - MixUp\n",
    "    - ensemble\n",
    "        - 8 TTA(vflip x hflip x rotate90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "- 2nd - https://www.kaggle.com/c/global-wheat-detection/discussion/175961\n",
    "    - code\n",
    "        - https://github.com/liaopeiyuan/TransferDet\n",
    "    - model\n",
    "        - <font color='red'>EfficientDet - D6</font>(pretrained w/ COCO dataset)\n",
    "            - D4ã€œD7ã¾ã§è©¦ã—ã¦D6ãŒæ€§èƒ½ãŒä¸€ç•ªè‰¯ã‹ã£ãŸ\n",
    "    - dataset\n",
    "        - image resolution: 1024x1024\n",
    "    - train\n",
    "        - augmentation\n",
    "            - crop, hue, random brightness/contrast\n",
    "            - to gray\n",
    "            - vertical and horizontal flip\n",
    "            - random rotate 90\n",
    "            - cutout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "- 3rd - https://www.kaggle.com/c/global-wheat-detection/discussion/179055\n",
    "    - code\n",
    "        - https://github.com/ufownl/global-wheat-detection\n",
    "    - model\n",
    "        - <font color='red'>Yolo v5</font>\n",
    "            - backbone: Darknet 53\n",
    "    - train\n",
    "        - max epochs: 9\n",
    "        - learning rate: 0.001\n",
    "        - batch size: 8\n",
    "        - image resolution: 512x512\n",
    "        - threshold: 0.1(ç‰©ä½“æ¤œå‡ºã®ãŸã‚ã®ã—ãã„å€¤)\n",
    "        - pseudo labeling\n",
    "            - cf. https://www.kaggle.com/ufownl/global-wheat-detection-pseudo-labaling\n",
    "    - post processing\n",
    "        - TTAã«WBF(Weighted boxes fusion)ã‚’åˆ©ç”¨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "- 5th - https://www.kaggle.com/c/global-wheat-detection/discussion/172458\n",
    "    - blog(æ—¥æœ¬èª)\n",
    "        - https://acro-engineer.hatenablog.com/entry/2020/08/21/175617\n",
    "    - dataset\n",
    "        - image resolution: 1024x1024\n",
    "    - models\n",
    "        - <font color='red'>EfficientDet D3 - D5</font>\n",
    "    - train\n",
    "        - 5 folds\n",
    "        - optimizer: AdamW\n",
    "        - max epoichs: 100\n",
    "        - batch size: 640\n",
    "        - pseudo labeling\n",
    "        - augmentation:\n",
    "            - mixup, mosaic, scale\n",
    "            - hue, brightness\n",
    "            - grid mask\n",
    "                - cf. https://arxiv.org/abs/2001.04086\n",
    "    - misc\n",
    "        - threshold: æ¤œå‡ºæ™‚ã®ã—ãã„å€¤ã‚’0.1ã«ã™ã‚Œã°ï¼Œ0.695å‡ºã¦ã„ãŸã‚‰ã—ã„"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "- 9th - https://www.kaggle.com/c/global-wheat-detection/discussion/172569\n",
    "    - code: \n",
    "        - https://github.com/amirassov/kaggle-global-wheat-detection\n",
    "    - dataset\n",
    "        - external data\n",
    "            - https://www.kaggle.com/c/global-wheat-detection/discussion/164346\n",
    "   ã€€- model\n",
    "        - <font color='red'>MMDetection</font> \n",
    "            - cf. https://github.com/open-mmlab/mmdetection\n",
    "    - train:\n",
    "        - augmentaion\n",
    "            - hflip, scale, shift, rotate90\n",
    "            - brightness/contrast, hue saturation, rgb shift\n",
    "            - random gamma\n",
    "            - clahe\n",
    "            - blur, motion blur\n",
    "            - gauss noise\n",
    "            - image compression\n",
    "            - coarse dropout\n",
    "            \n",
    "<img src=\"https://user-images.githubusercontent.com/846237/113238334-8ade7b80-92e3-11eb-840a-027a86d4fcc7.png\" width=\"600\">\n",
    "<img src=\"https://user-images.githubusercontent.com/846237/113238321-81edaa00-92e3-11eb-879e-be5e2cdc0d13.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "- 16th - https://www.kaggle.com/c/global-wheat-detection/discussion/172567\n",
    "    - train\n",
    "        - augmentaiton\n",
    "            - scale, mosaic, mixup, crop, cutout, hue, brightness, clahe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Top Notebooks\n",
    "\n",
    "- 2nd, https://www.kaggle.com/alexanderliao/effdet-d6-pl-s-bn-r-bb-a3-usa-eval-94-13-db\n",
    "    - EfficientDet - D6\n",
    "- 3rd, https://www.kaggle.com/x2x21x21x21/3rd-place-solution\n",
    "- 6th - https://www.kaggle.com/stonewst98/what-a-pity-only-0-0001-away-from-0-77\n",
    "    - Effficient Det\n",
    "- 9th - https://www.kaggle.com/amiras/pseudo-ensemble-detectors-3-st-universenet-r10\n",
    "- 13th - https://www.kaggle.com/dpyrtfq2372/efficientdet-with-double-psudo-labeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## æ¬¡ã«ã‚„ã‚‹ã¨è‰¯ã•ãã†ãªã‚³ãƒ³ãƒš\n",
    "\n",
    "- VinBigData Chest X-ray Abnormalities Detection\n",
    "   - ç‰©ä½“æ¤œå‡ºã‚³ãƒ³ãƒš\n",
    "   - åŒ»å¸«ã”ã¨ã«çŸ©å½¢ã®é ˜åŸŸãŒãƒãƒ©ãƒãƒ©ãªã®ã§ï¼Œã©ã†çµ±åˆã—ã¦ã„ãã‹å­¦ã¹ã¾ã™\n",
    "   - èƒ¸éƒ¨Xç·šã‹ã‚‰ã®ç•°å¸¸æ‰€è¦‹ã®åˆ†é¡\n",
    "   - https://www.kaggle.com/c/vinbigdata-chest-xray-abnormalities-detection"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
